from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col, when
from pyspark.sql.types import IntegerType, DateType
import datetime
from pyspark.sql.functions import to_date, lit

# Initialize Spark Session
spark = SparkSession.builder.appName('example').getOrCreate()

# Sample DataFrame
data = [
    ('user1', 'solution1', '2023-01-01', '2023-06-01'),
    ('user2', 'solution2', None, '2023-03-01'),
    ('user3', 'solution3', '2023-05-01', None),
    # Add your actual data here
]

columns = ['user_id', 'solution_name', 'open_date', 'close_date']

df = spark.createDataFrame(data, schema=columns)

# Convert string dates to DateType
df = df.withColumn('open_date', to_date(col('open_date')))
df = df.withColumn('close_date', to_date(col('close_date')))

# Define the function to calculate the label
def calculate_label(open_date, close_date, reference_date):
    if open_date is not None and open_date <= reference_date + datetime.timedelta(days=210):
        return 1
    elif close_date is not None and close_date < reference_date:
        return 0
    else:
        return None

# Register the UDF
calculate_label_udf = udf(calculate_label, IntegerType())

# Apply the function to each row
reference_date = datetime.date(2023, 1, 1)  # Replace with your actual reference date
df = df.withColumn(
    'label',
    calculate_label_udf(
        col('open_date'),
        col('close_date'),
        lit(reference_date)
    )
)

# Show the result
df.show()

