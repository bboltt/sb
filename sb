from pyspark.sql import SparkSession
from pyspark.sql.functions import col, min, max, sequence, to_date
import matplotlib.pyplot as plt

# Step 1: Initialize Spark Session
spark = SparkSession.builder.appName("FraudDetectionAnalysis").getOrCreate()

# Step 2: Load Data
# Replace `path_to_file` with your data file's path
data_path = "path_to_file.csv"
df = spark.read.csv(data_path, header=True, inferSchema=True)

# Ensure `trans_date` is in date format
df = df.withColumn("trans_date", to_date(col("trans_date"), "yyyy-MM-dd"))

# Step 3: Generate Complete Date Range
# Generate a sequence of dates from the minimum to the maximum date
date_range = df.select(
    sequence(min(col("trans_date")), max(col("trans_date"))).alias("date_seq")
)

# Explode the sequence into a DataFrame with all possible dates
complete_dates = date_range.selectExpr("explode(date_seq) as trans_date")

# Step 4: Outer Join to Include All Dates
# Perform an outer join between the complete date range and the original dataset
df_full = complete_dates.join(df, ["trans_date"], "left_outer")

# Step 5: Convert to Pandas for Interpolation
# Convert Spark DataFrame to Pandas
pandas_df = df_full.toPandas()

# Set `trans_date` as the index
pandas_df.set_index("trans_date", inplace=True)

# Interpolate missing values (linear interpolation for numerical columns)
pandas_df = pandas_df.interpolate(method="linear")

# Reset the index after interpolation
pandas_df.reset_index(inplace=True)

# Step 6: Plot Interpolated Time Series
# Example: Plotting the interpolated 'amount' column
plt.figure(figsize=(12, 6))
plt.plot(pandas_df["trans_date"], pandas_df["amount"], label="Interpolated Amount")
plt.title("Time Series with Interpolated Missing Dates")
plt.xlabel("Date")
plt.ylabel("Amount")
plt.legend()
plt.grid()
plt.show()


