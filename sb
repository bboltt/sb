def load_relevant_pwm_data(spark):
    """
    Loads the latest 6 months of data for `hh_id_in_wh` from the `dm_r3.pwm_mstr_dtl_daily` table,
    filtering to include only those identifiers marked as 'C. HIGH NET WORTH' in the
    `sb_dsp.pwm_customer_segmentation_final` table for a specific business date. It further refines
    the data to include records for `hh_id_in_wh` that have always been non-PWM or have switched
    to PWM within the last 6 months.

    Args:
        spark (SparkSession): An active SparkSession instance used to execute SQL queries.

    Returns:
        pandas.DataFrame: A Pandas DataFrame containing the filtered dataset based on the
        specified criteria.

    Note:
        The function executes a SQL query that incorporates a subquery for filtering based on
        the `sb_dsp.pwm_customer_segmentation_final` table. It assumes that the SparkSession has
        Hive support enabled for querying Hive tables directly.

    Example:
        >>> spark = SparkSession.builder.appName("YourAppName").enableHiveSupport().getOrCreate()
        >>> df = load_relevant_pwm_data(spark)
        >>> print(df.head())
    """
    query = """
    WITH LatestRecords AS (
        SELECT 
            hh_id_in_wh, 
            MAX(business_date) as latest_date
        FROM 
            dm_r3.pwm_mstr_dtl_daily
        GROUP BY 
            hh_id_in_wh
    ), RelevantHHIDs AS (
        SELECT DISTINCT
            d.hh_id_in_wh
        FROM 
            dm_r3.pwm_mstr_dtl_daily d
        JOIN 
            LatestRecords lr ON d.hh_id_in_wh = lr.hh_id_in_wh
        WHERE 
            d.hh_id_in_wh IN (
                SELECT DISTINCT hh_id_in_wh 
                FROM sb_dsp.pwm_customer_segmentation_final 
                WHERE new_wsegmt = 'C. HIGH NET WORTH' 
                AND business_date = '2023-10-31'
            )
            AND (
                (d.seg_code != 'PWM' AND d.business_date > ADD_MONTHS(lr.latest_date, -6))
                OR 
                (d.seg_code = 'PWM' AND d.business_date <= lr.latest_date AND d.business_date > ADD_MONTHS(lr.latest_date, -6))
            )
    )
    SELECT 
        d.*
    FROM 
        dm_r3.pwm_mstr_dtl_daily d
    JOIN 
        RelevantHHIDs r ON d.hh_id_in_wh = r.hh_id_in_wh
    WHERE 
        d.business_date > (SELECT ADD_MONTHS(MAX(business_date), -6) FROM dm_r3.pwm_mstr_dtl_daily)
    """
    spark_df = spark.sql(query)
    pandas_df = spark_df.toPandas()
    return pandas_df


