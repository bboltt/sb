from pyspark.sql.functions import col, when, count, avg

# Example: Average of a numeric feature grouped by pwm_relat
df.groupBy("pwm_relat").agg(avg("some_numeric_feature")).show()

# For categorical features, you can count occurrences by pwm_relat
df.groupBy("some_categorical_feature", "pwm_relat").count().show()


