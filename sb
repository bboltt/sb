import subprocess

# Command to list directories/files in HDFS location
hadoop_command = "hadoop fs -ls /path/to/hdfs/location"

# Run the command
process = subprocess.Popen(hadoop_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)

# Capture the command's output and error
(output, error) = process.communicate()

# Wait for the command to complete
process_status = process.wait()

if process_status == 0:
    # Command was successful, process the output
    output_lines = output.decode().strip().split('\n')

    # List to hold the file/directory paths
    paths = []

    for line in output_lines:
        # Typically, the file path is the last column in the output
        # Adjust the indexing if your output format is different
        parts = line.split()
        if len(parts) > 0:  # Making sure it's not an empty line
            path = parts[-1]  # The file/directory path is usually the last part
            paths.append(path)

    print("HDFS Paths:\n", paths)
else:
    # There was an error
    print("Command Error:\n", error.decode())
