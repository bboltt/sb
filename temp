from pyspark.sql.functions import udf
from pyspark.sql.types import ArrayType, FloatType
from pyspark.ml.linalg import Vectors

# Define a UDF to convert Vectors or Numpy arrays to Python lists
def vector_to_list(vector):
    return vector.toArray().tolist()  # Convert vector to array then to list

# Register the UDF with the appropriate return type
vector_to_list_udf = udf(vector_to_list, ArrayType(FloatType()))

# Apply the UDF to the DataFrame
centers_df = centers_df.withColumn("features", vector_to_list_udf("features"))

# Show the transformed DataFrame
centers_df.show(truncate=False)



def calculate_similarity(df, cluster_centers, features):
    """Calculate similarity of all clients to each cluster center."""
    for i, center in enumerate(cluster_centers.collect()):
        center_features = center['features']  # already a list now
        df = df.withColumn(f"similarity_to_cluster_{i}", cosine_similarity_udf(col("features"), array(center_features)))
    
    return df




from pyspark.sql.functions import udf, col
import numpy as np

def cosine_similarity(v1, v2):
    """ Compute the cosine similarity between two lists """
    v1 = np.array(v1)
    v2 = np.array(v2)
    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))

cosine_similarity_udf = udf(cosine_similarity)

def calculate_similarity(df, cluster_centers, features):
    # Assuming the features column is already in the desired format
    for i, center in enumerate(cluster_centers.collect()):
        center_features = center['features']
        df = df.withColumn(f"similarity_to_cluster_{i}", cosine_similarity_udf(col("features"), array(center_features)))
    
    return df


